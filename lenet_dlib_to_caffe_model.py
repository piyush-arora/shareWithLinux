#
# !!! This file was automatically generated by dlib's tools/convert_dlib_nets_to_caffe utility.     !!!
# !!! It contains all the information from a dlib DNN network and lets you save it as a cafe model. !!!
#
import caffe 
from caffe import layers as L, params as P
import numpy as np

# Input tensor dimensions
input_batch_size = 1;
input_num_channels = 1;
input_num_rows = 28;
input_num_cols = 28;

# Call this function to write the dlib DNN model out to file as a pair of caffe
# definition and weight files.  You can then use the network by loading it with
# this statement: 
#    net = caffe.Net(def_file, weights_file, caffe.TEST);
#
def save_as_caffe_model(def_file, weights_file):
    with open(def_file, 'w') as f: f.write(str(make_netspec()));
    net = caffe.Net(def_file, caffe.TEST);
    set_network_weights(net);
    net.save(weights_file);

###############################################################################
#         EVERYTHING BELOW HERE DEFINES THE DLIB MODEL PARAMETERS             #
###############################################################################


def make_netspec():
    # For reference, the only "documentation" about caffe layer parameters seems to be this page:
    # https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto

    n = caffe.NetSpec(); 
    n.data,n.label = L.MemoryData(batch_size=input_batch_size, channels=input_num_channels, height=input_num_rows, width=input_num_cols, ntop=2)
    n.con11 = L.Convolution(n.data, num_output=6, kernel_w=5, kernel_h=5, stride_w=1, stride_h=1, pad_w=2, pad_h=2);
    n.relu10 = L.ReLU(n.con11);
    n.max_pool9 = L.Pooling(n.relu10, pool=P.Pooling.MAX, kernel_w=2, kernel_h=2, stride_w=2, stride_h=2, pad_w=0, pad_h=0);
    n.con8 = L.Convolution(n.max_pool9, num_output=16, kernel_w=5, kernel_h=5, stride_w=1, stride_h=1, pad_w=2, pad_h=2);
    n.relu7 = L.ReLU(n.con8);
    n.max_pool6 = L.Pooling(n.relu7, pool=P.Pooling.MAX, kernel_w=2, kernel_h=2, stride_w=2, stride_h=2, pad_w=0, pad_h=0);
    n.fc5 = L.InnerProduct(n.max_pool6, num_output=120, bias_term=True);
    n.relu4 = L.ReLU(n.fc5);
    n.fc3 = L.InnerProduct(n.relu4, num_output=84, bias_term=True);
    n.relu2 = L.ReLU(n.fc3);
    n.fc1 = L.InnerProduct(n.relu2, num_output=10, bias_term=True);
    return n.to_proto();


def set_network_weights(net):
    # populate network parameters
    f = open('lenet_dlib_to_caffe_model.weights', 'rb');
    p = np.fromfile(f, dtype='float32', count=150);
    p.shape = net.params['con11'][0].data.shape;
    net.params['con11'][0].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=6);
    p.shape = net.params['con11'][1].data.shape;
    net.params['con11'][1].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=2400);
    p.shape = net.params['con8'][0].data.shape;
    net.params['con8'][0].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=16);
    p.shape = net.params['con8'][1].data.shape;
    net.params['con8'][1].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=94080);
    p.shape = net.params['fc5'][0].data.shape;
    net.params['fc5'][0].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=120);
    p.shape = net.params['fc5'][1].data.shape;
    net.params['fc5'][1].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=10080);
    p.shape = net.params['fc3'][0].data.shape;
    net.params['fc3'][0].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=84);
    p.shape = net.params['fc3'][1].data.shape;
    net.params['fc3'][1].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=840);
    p.shape = net.params['fc1'][0].data.shape;
    net.params['fc1'][0].data[:] = p;
    p = np.fromfile(f, dtype='float32', count=10);
    p.shape = net.params['fc1'][1].data.shape;
    net.params['fc1'][1].data[:] = p;
